# Local LLM Modular Resource

`local-llm` is a modular resource that provides local LLM inference capabilities for machines running on the Viam platform.

## Prerequisites

## Config

## Usage

## Contributing 
