{
  "module_id": "viam-labs:llm",
  "visibility": "public",
  "url": "https://github.com/viam-labs/local-llm-module",
  "description": "A Viam module for inferencing a local LLM.",
  "models": [
    {
      "api": "viam-labs:service:chat",
      "model": "viam-labs:chat:llm"
    }
  ],
  "entrypoint": "run.sh"
}
